{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa4daf0-04ce-4fe8-8780-46e09d239f06",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sqlite3\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from visualize_model import Model\n",
        "from database import blob_to_array, pair_id_to_image_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25bfed4a-95ed-4c25-ae03-dfa1be34bfa4",
      "metadata": {},
      "source": [
        "# 1. 3D mesh reconstruction from a set of images from the Gerrard Hall dataset.\n",
        "First, we installed Colmap and runned the automatic reconstruction on the Gerrard Hall dataset. \n",
        "\n",
        "After running the automatic reconstruction, we visualized the sparse reconstruction directly in COLMAP. This visualization shows the recovered camera poses (in red) and the 3D sparse point cloud representing the structure of the scene. \n",
        "\n",
        "<div style=\"display: flex; gap: 10px;\">\n",
        "  <img src=\"figures/gerrard_hall_colmap.png\" width=\"45%\">\n",
        "</div style=\"gap: 10px;\">\n",
        "\n",
        "Next, we exported the dense reconstruction and loaded the resulting meshes into MeshLab for further visualization and processing.\n",
        "\n",
        "<div style=\"display: flex; gap: 10px;\">\n",
        "  <img src=\"figures/gerrard_hall_mesh_before_1.png\" width=\"45%\">\n",
        "  <img src=\"figures/gerrard_hall_mesh_before_2.png\" width=\"45%\">\n",
        "</div style=\"gap: 10px;\">\n",
        "\n",
        "However, the raw mesh contained several artifacts and noisy components, especially around the borders and less constrained regions. To improve the final result, we applied different cleaning filters in MeshLab, such as removing isolated components, and manually removed a connected region that corresponded to a reconstruction artifact. The following images correspond to the cleaned versions of the previous meshes, obtained after applying post-processing steps in MeshLab.\n",
        "\n",
        "<div style=\"display: flex; gap: 10px;\">\n",
        "  <img src=\"figures/gerrard_hall_mesh_after_1.png\" width=\"45%\">\n",
        "  <img src=\"figures/gerrard_hall_mesh_after_2.png\" width=\"45%\">\n",
        "</div style=\"gap: 10px;\">\n",
        "\n",
        "The final processed mesh can be downloaded from the following link:\n",
        "[Gerrard Hall Mesh](https://drive.google.com/file/d/1yNNZeB9sxfI0jd5833KQu7Z_Lk0r3WLD/view?usp=drive_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19c31494-3050-4951-aed1-b463f3fba821",
      "metadata": {},
      "source": [
        "# 2. Analyze reconstructions using python\n",
        "## 2.1. Run the notebook, using the Gerrard Hall reconstruction (0.5)\n",
        "#### <span style='color:Green'> - Add the path to your reconstruction. Answer the questions at the end  </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41796fd2-2304-487f-a74c-3f1a51ad83f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add your path\n",
        "reconstruction_path = \"/home/arnau-marcos-almansa/workspace/MCV-C4/lab4/gerrard_hall/images/sparse/0\"\n",
        "database_path = \"/home/arnau-marcos-almansa/workspace/MCV-C4/lab4/gerrard_hall/images/database.db\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a701bb3-945a-434c-880c-849dad97a97d",
      "metadata": {},
      "source": [
        "#### Load an existing reconstruction and print its contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf644962-ba41-403f-a1a4-3e1b08d16151",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Model()\n",
        "# model.read_model(reconstruction_path, ext='.bin') # Should also work with .txt\n",
        "model.read_model(reconstruction_path, ext='.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b629e852-0407-4eff-ba62-b9d1d51015bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "images = model.images\n",
        "cameras = model.cameras\n",
        "points3D = model.points3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca47fb58-dbcd-4c6f-8168-e296832aacf5",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(f\"Loaded {len(images)} images. This is the information available for one of them:\")\n",
        "print(images[1])\n",
        "print(f\"\\nLoaded {len(cameras)} cameras. This is the information available for one of them:\")\n",
        "print(cameras[1])\n",
        "print(f\"\\nLoaded {len(points3D)} 3D points. This is the information available for one of them:\")\n",
        "# print(points3D[1]) # TODO: FIX THIS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce97039-6c3e-40e9-af81-e0795fc5b41a",
      "metadata": {
        "tags": []
      },
      "source": [
        "#### Load the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b74d1dde-024f-47b6-85cc-99f0801f414c",
      "metadata": {},
      "outputs": [],
      "source": [
        "db = sqlite3.connect(database_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6ff5d3-a33f-41f5-882d-d370bf3dd489",
      "metadata": {},
      "outputs": [],
      "source": [
        "keypoints = dict(\n",
        "        (image_id, blob_to_array(data, np.float32, (-1, 2)))\n",
        "        for image_id, data in db.execute(\n",
        "            \"SELECT image_id, data FROM keypoints\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c843a569-d812-4bfe-8f61-e68cc9d9dfbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Loaded keypoints from {len(keypoints)} images. These are the {len(keypoints[1])} keypoints for one of them:\")\n",
        "print(keypoints[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f31f2a-d3b3-48af-b0cc-1276f5cfe177",
      "metadata": {},
      "outputs": [],
      "source": [
        "matches = dict()\n",
        "count_no_data = 0\n",
        "for pair_id, data in db.execute(\"SELECT pair_id, data FROM matches\"):\n",
        "    if data is None:\n",
        "        count_no_data += 1\n",
        "    else:\n",
        "        matches[pair_id_to_image_ids(pair_id)] = blob_to_array(data, np.uint32, (-1, 2))\n",
        "print(f\"Loaded {len(matches)} matches. {count_no_data}/{len(matches)+count_no_data} matches contained no data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac8472b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal\n",
        "\n",
        "dir(matches)\n",
        "matches.__class__\n",
        "matches.items()\n",
        "matches.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa07761b-eaec-488d-b1e9-36720e203a31",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"These are the matches between two images:\")\n",
        "print(matches[1,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a12c0675-6841-4519-b79f-cc2b811b94fd",
      "metadata": {},
      "source": [
        "#### Visualize the point cloud and cameras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb95e07c-b1d6-4f08-8842-8fc41b676a10",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.create_window()\n",
        "model.add_points()\n",
        "model.add_cameras(scale=0.25)\n",
        "model.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d5e272-83de-4136-b047-885051bd7e78",
      "metadata": {},
      "source": [
        "#### <span style='color:Green'>  How many keypoints there are in total? </span> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73905673",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"#Keypoints total: {sum(kpts.shape[0] for kpts in keypoints.values())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c782bbf7",
      "metadata": {},
      "source": [
        "<span style='color:darkcyan'>There are 3112449 keypoints in total.</span> "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c13142-d04b-4f48-9b28-5e78b9c72a8b",
      "metadata": {},
      "source": [
        "#### <span style='color:Green'>  How many 3D points originated from a keypoint in the first image? </span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d1b7c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_points3d_originated_in_image_1 = sum(1 for point3D in points3D.values() if 1 in point3D.image_ids)\n",
        "\n",
        "print(f\"#3d points from image 1: {num_points3d_originated_in_image_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acd85b6f",
      "metadata": {},
      "source": [
        "<span style='color:darkcyan'>There are 3210 keypoints in image 1.</span> "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "075a83ca-0ad4-493f-a7b7-9e11ae8153c0",
      "metadata": {},
      "source": [
        "## 2.2 Plot the 3D points coloured according to the number of images and error. (0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6803fb41-cb01-43c2-9853-9f4458640a75",
      "metadata": {},
      "source": [
        "#### <span style='color:Green'> - Plot the 3D points coloured according to the **number of images** from which it originated. </span> Can you extract any conclusions from the visualization? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d55db2-d7b4-4eda-91c2-8b2001fbf6e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "### TO DO 2.2\n",
        "\n",
        "xyz = []\n",
        "num_images = []\n",
        "errors = []\n",
        "\n",
        "for point3D in points3D.values():\n",
        "    xyz.append(point3D.xyz)\n",
        "    num_images.append(len(point3D.image_ids))\n",
        "    errors.append(point3D.error)\n",
        "\n",
        "xyz = np.array(xyz)\n",
        "num_images = np.array(num_images)\n",
        "errors = np.array(errors)\n",
        "\n",
        "num_images_norm = (num_images - num_images.min()) / (num_images.max() - num_images.min())\n",
        "errors_norm = (errors - errors.min()) / (errors.max() - errors.min())\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "colors_by_images = cm.jet(num_images_norm)[:, :3]\n",
        "colors_by_error = cm.jet(errors_norm)[:, :3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "240545d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 1))\n",
        "fig.subplots_adjust(bottom=0.5)\n",
        "\n",
        "norm = plt.Normalize(vmin=num_images.min(), vmax=num_images.max())\n",
        "cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap='jet'), \n",
        "                    cax=ax, orientation='horizontal')\n",
        "cbar.set_label('Number of images')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e4a222",
      "metadata": {},
      "outputs": [],
      "source": [
        "import open3d\n",
        "\n",
        "\n",
        "vis = open3d.visualization.Visualizer()\n",
        "vis.create_window()\n",
        "\n",
        "pcd = open3d.geometry.PointCloud()\n",
        "\n",
        "pcd.points = open3d.utility.Vector3dVector(xyz)\n",
        "pcd.colors = open3d.utility.Vector3dVector(colors_by_images)\n",
        "\n",
        "vis.add_geometry(pcd)\n",
        "vis.poll_events()\n",
        "vis.update_renderer()\n",
        "\n",
        "vis.poll_events()\n",
        "vis.update_renderer()\n",
        "vis.run()\n",
        "vis.destroy_window()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db190967",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's plot a histogram too\n",
        "\n",
        "images_per_point3d = [len(p3d.image_ids) for p3d in points3D.values()]\n",
        "counts, bins = np.histogram(images_per_point3d, bins=[i for i in range(max(images_per_point3d) + 1)])\n",
        "_ = plt.hist(bins[:-1], bins, weights=counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19cc260",
      "metadata": {},
      "source": [
        "<span style='color:darkcyan'>Most points are visible from a few images. MORE</span> "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9ba4033-e370-45e0-9dcd-2964d3c5763a",
      "metadata": {},
      "source": [
        "#### <span style='color:Green'> - Plot the 3D points coloured according to the **error**. </span> - What is this parameter? Can you extract any conclusions from the visualization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b23532f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 1))\n",
        "fig.subplots_adjust(bottom=0.5)\n",
        "\n",
        "norm = plt.Normalize(vmin=errors_norm.min(), vmax=errors_norm.max())\n",
        "cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap='jet'), \n",
        "                    cax=ax, orientation='horizontal')\n",
        "cbar.set_label('Error')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb29f94-1864-4e21-b534-7eb681dd9057",
      "metadata": {},
      "outputs": [],
      "source": [
        "### TO DO 2.2\n",
        "\n",
        "import open3d\n",
        "\n",
        "\n",
        "vis = open3d.visualization.Visualizer()\n",
        "vis.create_window()\n",
        "\n",
        "pcd = open3d.geometry.PointCloud()\n",
        "\n",
        "pcd.points = open3d.utility.Vector3dVector(xyz)\n",
        "pcd.colors = open3d.utility.Vector3dVector(colors_by_error)\n",
        "\n",
        "vis.add_geometry(pcd)\n",
        "vis.poll_events()\n",
        "vis.update_renderer()\n",
        "\n",
        "vis.poll_events()\n",
        "vis.update_renderer()\n",
        "vis.run()\n",
        "vis.destroy_window()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d01f26e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's plot a histogram too\n",
        "\n",
        "error_per_point3d = [p3d.error for p3d in points3D.values()]\n",
        "counts, bins = np.histogram(error_per_point3d)\n",
        "_ = plt.hist(bins[:-1], bins, weights=counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9a36ce4",
      "metadata": {},
      "source": [
        "<span style='color:darkcyan'>The error property of a 3D point is the average reprojection error of the point accross all images that can see said point.</span> \n",
        "\n",
        "<span style='color:darkcyan'>The error of the 3D points seems to have a more normal distribution. MORE</span> "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbe177d5-893b-41b4-aa1c-6d6fb06b54b7",
      "metadata": {},
      "source": [
        "## 2.3 Plot the 3D points that correspond to a keypoint in the first image. Also plot the image with the keypoints (1.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1888156a-c5f5-4695-a75b-2883f1a7c8b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "### TO DO 2.3\n",
        "\n",
        "xyz = []\n",
        "colors = []\n",
        "\n",
        "for point3D in points3D.values():\n",
        "    if 1 not in point3D.image_ids:\n",
        "        continue\n",
        "    xyz.append(point3D.xyz)\n",
        "    colors.append(point3D.rgb / 255)\n",
        "\n",
        "vis = open3d.visualization.Visualizer()\n",
        "vis.create_window()\n",
        "\n",
        "pcd = open3d.geometry.PointCloud()\n",
        "\n",
        "pcd.points = open3d.utility.Vector3dVector(xyz)\n",
        "pcd.colors = open3d.utility.Vector3dVector(colors)\n",
        "\n",
        "vis.add_geometry(pcd)\n",
        "vis.poll_events()\n",
        "vis.update_renderer()\n",
        "\n",
        "vis.poll_events()\n",
        "vis.update_renderer()\n",
        "vis.run()\n",
        "vis.destroy_window()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea7ff3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "image1_keypoints = keypoints[1]\n",
        "\n",
        "cv_keypoints = [cv2.KeyPoint(x=float(pt[0]), y=float(pt[1]), size=50) \n",
        "                for pt in image1_keypoints]\n",
        "\n",
        "\n",
        "images_path = \"/home/arnau-marcos-almansa/workspace/MCV-C4/lab4/gerrard_hall/images/\"\n",
        "\n",
        "print(type(image1_keypoints))\n",
        "print(image1_keypoints.shape)\n",
        "print(image1_keypoints.dtype)\n",
        "\n",
        "print(type(images[1]))\n",
        "\n",
        "im1 = cv2.imread(images_path + images[1].name)\n",
        "print(type(im1))\n",
        "im_with_kpts = cv2.drawKeypoints(im1, cv_keypoints, None, \n",
        "                                   color=(255, 0, 255),\n",
        "                                   flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "plt.imshow(cv2.cvtColor(im_with_kpts, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e117ea99-bc47-41f6-8b14-a42213ee0482",
      "metadata": {},
      "source": [
        "## 2.4 Create a visualization for the number of matches between all images. (1.0)\n",
        "For example: https://seaborn.pydata.org/generated/seaborn.heatmap.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13fba504-a871-4287-9833-46aa1c883637",
      "metadata": {},
      "outputs": [],
      "source": [
        "### TO DO 2.4\n",
        "\n",
        "num_images = max(images.keys())\n",
        "match_matrix = np.zeros((num_images, num_images), dtype=np.int32)\n",
        "for (id1, id2), match_data in matches.items():\n",
        "    i, j = int(id1) - 1, int(id2) - 1\n",
        "    num_matches = len(match_data)\n",
        "    match_matrix[i, j] = num_matches\n",
        "    match_matrix[j, i] = num_matches\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(match_matrix, xticklabels=10, yticklabels=10)\n",
        "plt.xlabel('Image Id')\n",
        "plt.ylabel('Image Id')\n",
        "plt.title('Number of matches between images')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc84087",
      "metadata": {},
      "source": [
        "<span style='color:darkcyan'>Matches are concentrated around each image. An image won't have matches with images too far apart, as they represent different parts of the scene - images far appart may show different facades of the building. The fact that the corners of the heatmap are not 0 indicates that the last few images match with the first ones, indicating a somewhat closed track.</span> "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ab06d62-e966-439e-87d7-5d7ba973bca1",
      "metadata": {},
      "source": [
        "## 2.5 Visualize the keypoints and matches between the two images used in lab 3 using Colmap, how it compares to the results from lab 3? (1.0)\n",
        "#### <span style='color:Green'> You can use the GUI to get the keypoints and matches and then visualize it here, following the same style as in lab 3 to get comparable results. </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f50cc03b-672c-491c-bd61-e40bcc757f43",
      "metadata": {},
      "outputs": [],
      "source": [
        "### TO DO 2.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "244a4a42-5c40-4983-af8a-2c0ef286ce5d",
      "metadata": {},
      "source": [
        "## 2.6 Triangulate and visualize the 3D points from the keypoints extracted using Colmap on the two images used in lab 3, how it compares to the results from lab 3? (1.0) \n",
        "#### <span style='color:Green'> - Use the triangulation from lab 3 to the get the 3D points and visualize them following the same style. </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5abc66ad-ab36-4192-b93b-8523adfb3620",
      "metadata": {},
      "outputs": [],
      "source": [
        "### TO DO 2.6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10eacbca-842d-4d9e-85bd-efc35c5dd15a",
      "metadata": {},
      "source": [
        "## 2.7 Visualize the sparse reconstruction using the 2 images from lab 3, and the complete CASTLE dataset. Comment on the differences between techniques and number of images used. (1.0)\n",
        "#### <span style='color:Green'> - Use the reconstruction from Colmap to the get the 3D points and visualize them following the same style, using two images and the complete dataset. </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b9504a3-dcbf-4b2b-9ff6-71c5a4584742",
      "metadata": {},
      "outputs": [],
      "source": [
        "### TO DO 2.7"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
