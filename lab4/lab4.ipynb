{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa4daf0-04ce-4fe8-8780-46e09d239f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sqlite3\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from visualize_model import Model\n",
    "from database import blob_to_array, pair_id_to_image_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfed4a-95ed-4c25-ae03-dfa1be34bfa4",
   "metadata": {},
   "source": [
    "# 1. 3D mesh reconstruction from a set of images from the Gerrard Hall dataset.\n",
    "First, we installed Colmap and runned the automatic reconstruction on the Gerrard Hall dataset. \n",
    "\n",
    "After running the automatic reconstruction, we visualized the sparse reconstruction directly in COLMAP. This visualization shows the recovered camera poses (in red) and the 3D sparse point cloud representing the structure of the scene. \n",
    "\n",
    "<div style=\"display: flex; gap: 10px;\">\n",
    "  <img src=\"figures/gerrard_hall_colmap.png\" width=\"45%\">\n",
    "</div style=\"gap: 10px;\">\n",
    "\n",
    "Next, we exported the dense reconstruction and loaded the resulting meshes into MeshLab for further visualization and processing.\n",
    "\n",
    "<div style=\"display: flex; gap: 10px;\">\n",
    "  <img src=\"figures/gerrard_hall_mesh_before_1.png\" width=\"45%\">\n",
    "  <img src=\"figures/gerrard_hall_mesh_before_2.png\" width=\"45%\">\n",
    "</div style=\"gap: 10px;\">\n",
    "\n",
    "However, the raw mesh contained several artifacts and noisy components, especially around the borders and less constrained regions. To improve the final result, we applied different cleaning filters in MeshLab, such as removing isolated components, and manually removed a connected region that corresponded to a reconstruction artifact. The following images correspond to the cleaned versions of the previous meshes, obtained after applying post-processing steps in MeshLab.\n",
    "\n",
    "<div style=\"display: flex; gap: 10px;\">\n",
    "  <img src=\"figures/gerrard_hall_mesh_after_1.png\" width=\"45%\">\n",
    "  <img src=\"figures/gerrard_hall_mesh_after_2.png\" width=\"45%\">\n",
    "</div style=\"gap: 10px;\">\n",
    "\n",
    "The final processed mesh can be downloaded from the following link:\n",
    "[Gerrard Hall Mesh](https://drive.google.com/file/d/1yNNZeB9sxfI0jd5833KQu7Z_Lk0r3WLD/view?usp=drive_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c31494-3050-4951-aed1-b463f3fba821",
   "metadata": {},
   "source": [
    "# 2. Analyze reconstructions using python\n",
    "## 2.1. Run the notebook, using the Gerrard Hall reconstruction (0.5)\n",
    "#### <span style='color:Green'> - Add the path to your reconstruction. Answer the questions at the end  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41796fd2-2304-487f-a74c-3f1a51ad83f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your path\n",
    "reconstruction_path = \"./gerrard_hall\"\n",
    "database_path = \"./gerrard-hall/database.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a701bb3-945a-434c-880c-849dad97a97d",
   "metadata": {},
   "source": [
    "#### Load an existing reconstruction and print its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf644962-ba41-403f-a1a4-3e1b08d16151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.read_model(reconstruction_path, ext='.bin') # Should also work with .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b629e852-0407-4eff-ba62-b9d1d51015bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = model.images\n",
    "cameras = model.cameras\n",
    "points3D = model.points3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca47fb58-dbcd-4c6f-8168-e296832aacf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 images. This is the information available for one of them:\n",
      "Image(id=1, qvec=array([ 0.63708369,  0.22429394, -0.25600195,  0.69157762]), tvec=array([-0.72194622, -1.9670957 ,  2.73841702]), camera_id=1, name='IMG_2387.JPG', xys=array([[ 758.38574219,   61.36777496],\n",
      "       [2757.86962891,   11.28521633],\n",
      "       [2775.62963867,   33.56768417],\n",
      "       ...,\n",
      "       [1864.0871582 , 3612.57421875],\n",
      "       [2398.2121582 , 3603.64233398],\n",
      "       [2398.2121582 , 3603.64233398]]), point3D_ids=array([-1, -1, -1, ..., -1, -1, -1]))\n",
      "\n",
      "Loaded 1 cameras. This is the information available for one of them:\n",
      "Camera(id=1, model='OPENCV', width=5616, height=3744, params=array([ 3.83803963e+03,  3.83703349e+03,  2.80800000e+03,  1.87200000e+03,\n",
      "       -1.10256401e-01,  7.93806018e-02,  1.17244277e-04,  2.84898767e-04]))\n",
      "\n",
      "Loaded 42815 3D points. This is the information available for one of them:\n",
      "Point3D(id=1, xyz=array([-0.03336308, -1.54452335, -1.58907061]), rgb=array([205, 210, 213]), error=array(0.39630917), image_ids=array([27, 70, 63,  3]), point2D_idxs=array([  27, 2421,   29,  362]))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(images)} images. This is the information available for one of them:\")\n",
    "print(images[1])\n",
    "print(f\"\\nLoaded {len(cameras)} cameras. This is the information available for one of them:\")\n",
    "print(cameras[1])\n",
    "print(f\"\\nLoaded {len(points3D)} 3D points. This is the information available for one of them:\")\n",
    "print(points3D[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce97039-6c3e-40e9-af81-e0795fc5b41a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b74d1dde-024f-47b6-85cc-99f0801f414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc6ff5d3-a33f-41f5-882d-d370bf3dd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = dict(\n",
    "        (image_id, blob_to_array(data, np.float32, (-1, 2)))\n",
    "        for image_id, data in db.execute(\n",
    "            \"SELECT image_id, data FROM keypoints\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c843a569-d812-4bfe-8f61-e68cc9d9dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keypoints from 100 images. These are the 24414 keypoints for one of them:\n",
      "[[7.5838574e+02 6.1367775e+01]\n",
      " [4.0777049e+00 2.3697526e+00]\n",
      " [2.7578696e+03 1.1285216e+01]\n",
      " ...\n",
      " [4.2930962e+01 4.8993421e+00]\n",
      " [2.3982122e+03 3.6036423e+03]\n",
      " [4.2930962e+01 2.5109098e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded keypoints from {len(keypoints)} images. These are the {len(keypoints[1])} keypoints for one of them:\")\n",
    "print(keypoints[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27f31f2a-d3b3-48af-b0cc-1276f5cfe177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2153 matches. 2797/4950 matches contained no data\n"
     ]
    }
   ],
   "source": [
    "matches = dict()\n",
    "count_no_data = 0\n",
    "for pair_id, data in db.execute(\"SELECT pair_id, data FROM matches\"):\n",
    "    if data is None:\n",
    "        count_no_data += 1\n",
    "    else:\n",
    "        matches[pair_id_to_image_ids(pair_id)] = blob_to_array(data, np.uint32, (-1, 2))\n",
    "print(f\"Loaded {len(matches)} matches. {count_no_data}/{len(matches)+count_no_data} matches contained no data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa07761b-eaec-488d-b1e9-36720e203a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the matches between two images:\n",
      "[[1459   68]\n",
      " [8054  481]\n",
      " [8113  482]\n",
      " [8114  483]\n",
      " [8187  484]\n",
      " [6590  512]\n",
      " [8009  603]\n",
      " [8053  608]\n",
      " [8184  611]\n",
      " [8111  612]\n",
      " [8112  613]\n",
      " [8052  774]\n",
      " [8182  775]\n",
      " [8181  777]\n",
      " [5326  783]\n",
      " [5806  797]\n",
      " [8005  903]\n",
      " [8107  907]\n",
      " [8110  909]\n",
      " [8048  910]\n",
      " [8049  911]\n",
      " [8180  914]\n",
      " [8177  915]\n",
      " [8175  916]\n",
      " [5067  917]\n",
      " [8178  919]\n",
      " [5800  926]\n",
      " [6416  939]\n",
      " [8002 1041]\n",
      " [8000 1043]\n",
      " [8001 1044]\n",
      " [8044 1050]\n",
      " [5684 1062]\n",
      " [7995 1191]\n",
      " [8104 1192]\n",
      " [8099 1194]\n",
      " [8097 1196]\n",
      " [8100 1197]\n",
      " [8096 1198]\n",
      " [8169 1200]\n",
      " [8171 1201]\n",
      " [6658 1223]\n",
      " [8039 1339]\n",
      " [8092 1340]\n",
      " [8088 1341]\n",
      " [8094 1342]\n",
      " [8168 1343]\n",
      " [6477 1384]\n",
      " [7172 1397]\n",
      " [7173 1398]\n",
      " [7170 1399]\n",
      " [7168 1400]\n",
      " [7994 1491]\n",
      " [7991 1492]\n",
      " [7992 1493]\n",
      " [8036 1496]\n",
      " [7993 1498]\n",
      " [8087 1505]\n",
      " [5912 1525]\n",
      " [7003 1549]\n",
      " [7002 1550]\n",
      " [7986 1684]\n",
      " [8032 1685]\n",
      " [8165 1687]\n",
      " [8163 1688]\n",
      " [6570 1709]\n",
      " [6565 1710]\n",
      " [7237 1735]\n",
      " [8033 1855]\n",
      " [8031 1856]\n",
      " [8086 1857]\n",
      " [8085 1858]\n",
      " [8162 1860]\n",
      " [5436 1870]\n",
      " [5786 1883]\n",
      " [6277 1887]\n",
      " [6561 1898]\n",
      " [6759 1904]\n",
      " [6760 1905]\n",
      " [6856 1908]\n",
      " [6914 1910]\n",
      " [7072 1917]\n",
      " [7231 1918]\n",
      " [7976 2041]\n",
      " [8030 2042]\n",
      " [8028 2043]\n",
      " [8026 2044]\n",
      " [8076 2045]\n",
      " [8079 2046]\n",
      " [8159 2048]\n",
      " [8025 2049]\n",
      " [8075 2050]\n",
      " [8074 2051]\n",
      " [8158 2055]\n",
      " [8156 2058]\n",
      " [6384 2086]\n",
      " [6463 2094]\n",
      " [6995 2106]\n",
      " [8024 2218]\n",
      " [8023 2219]\n",
      " [7974 2221]\n",
      " [7968 2222]\n",
      " [4937 2224]\n",
      " [4938 2225]\n",
      " [8153 2227]\n",
      " [8069 2228]\n",
      " [8073 2229]\n",
      " [8148 2231]\n",
      " [6148 2269]\n",
      " [6267 2271]\n",
      " [6548 2282]\n",
      " [6453 2283]\n",
      " [6701 2289]\n",
      " [7969 2389]\n",
      " [7970 2390]\n",
      " [8068 2393]\n",
      " [8070 2394]\n",
      " [5027 2397]\n",
      " [8147 2398]\n",
      " [8146 2399]\n",
      " [8145 2401]\n",
      " [8150 2402]\n",
      " [8143 2403]\n",
      " [5023 2404]\n",
      " [5530 2415]\n",
      " [6449 2442]\n",
      " [6450 2443]\n",
      " [7143 2460]\n",
      " [7149 2462]\n",
      " [6442 2562]\n",
      " [2618 2564]\n",
      " [2698 2572]\n",
      " [8064 2587]\n",
      " [8144 2589]\n",
      " [8135 2594]\n",
      " [1737 2610]\n",
      " [5775 2611]\n",
      " [6137 2617]\n",
      " [6696 2637]\n",
      " [6980 2641]\n",
      " [6908 2642]\n",
      " [6979 2643]\n",
      " [7063 2646]\n",
      " [7058 2647]\n",
      " [6018 2785]\n",
      " [6023 2788]\n",
      " [6747 2797]\n",
      " [6906 2803]\n",
      " [7052 2806]\n",
      " [7134 2811]\n",
      " [7135 2812]\n",
      " [5886 2925]\n",
      " [6015 2935]\n",
      " [7050 2953]\n",
      " [6003 3074]\n",
      " [6237 3084]\n",
      " [6244 3093]\n",
      " [5250 3197]\n",
      " [6834 3219]\n",
      " [7932 3237]\n",
      " [7933 3238]\n",
      " [5112 3302]\n",
      " [5634 3316]\n",
      " [5633 3317]\n",
      " [6831 3337]\n",
      " [6220 3452]\n",
      " [6221 3453]\n",
      " [6116 3455]\n",
      " [7040 3470]\n",
      " [7032 3471]\n",
      " [7035 3472]\n",
      " [5742 3597]\n",
      " [5743 3600]\n",
      " [6113 3611]\n",
      " [6105 3612]\n",
      " [6211 3618]\n",
      " [6886 3629]\n",
      " [6817 3631]\n",
      " [6953 3634]\n",
      " [8129 3731]\n",
      " [6207 3751]\n",
      " [6512 3760]\n",
      " [6807 3763]\n",
      " [6888 3769]\n",
      " [6944 3779]\n",
      " [7410 3803]\n",
      " [5978 3930]\n",
      " [5977 3932]\n",
      " [6937 3953]\n",
      " [7018 3963]\n",
      " [8124 4079]\n",
      " [5972 4093]\n",
      " [5836 4095]\n",
      " [6681 4108]\n",
      " [6796 4111]\n",
      " [8121 4199]\n",
      " [5724 4204]\n",
      " [ 872 4207]\n",
      " [6928 4232]\n",
      " [6929 4244]\n",
      " [5826 4358]\n",
      " [ 500 4408]\n",
      " [7746 4763]\n",
      " [8174 5015]\n",
      " [8084 5582]\n",
      " [8152 5801]\n",
      " [ 317 6049]\n",
      " [6737 6177]\n",
      " [6738 6178]\n",
      " [3862 6248]\n",
      " [4535 6652]\n",
      " [6516 6721]\n",
      " [6596 6836]\n",
      " [6597 6837]\n",
      " [7395 6880]\n",
      " [6436 7061]\n",
      " [3279 8141]]\n"
     ]
    }
   ],
   "source": [
    "print(\"These are the matches between two images:\")\n",
    "print(matches[1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c0675-6841-4519-b79f-cc2b811b94fd",
   "metadata": {},
   "source": [
    "#### Visualize the point cloud and cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb95e07c-b1d6-4f08-8842-8fc41b676a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_window()\n",
    "model.add_points()\n",
    "model.add_cameras(scale=0.25)\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5e272-83de-4136-b047-885051bd7e78",
   "metadata": {},
   "source": [
    "#### <span style='color:Green'>  How many keypoints there are in total? </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c13142-d04b-4f48-9b28-5e78b9c72a8b",
   "metadata": {},
   "source": [
    "#### <span style='color:Green'>  How many 3D points originated from a keypoint in the first image? </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a83ca-0ad4-493f-a7b7-9e11ae8153c0",
   "metadata": {},
   "source": [
    "## 2.2 Plot the 3D points coloured according to the number of images and error. (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803fb41-cb01-43c2-9853-9f4458640a75",
   "metadata": {},
   "source": [
    "#### <span style='color:Green'> - Plot the 3D points coloured according to the **number of images** from which it originated. </span> Can you extract any conclusions from the visualization? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d55db2-d7b4-4eda-91c2-8b2001fbf6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba4033-e370-45e0-9dcd-2964d3c5763a",
   "metadata": {},
   "source": [
    "#### <span style='color:Green'> - Plot the 3D points coloured according to the **error**. </span> - What is this parameter? Can you extract any conclusions from the visualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb29f94-1864-4e21-b534-7eb681dd9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe177d5-893b-41b4-aa1c-6d6fb06b54b7",
   "metadata": {},
   "source": [
    "## 2.3 Plot the 3D points that correspond to a keypoint in the first image. Also plot the image with the keypoints (1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888156a-c5f5-4695-a75b-2883f1a7c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e117ea99-bc47-41f6-8b14-a42213ee0482",
   "metadata": {},
   "source": [
    "## 2.4 Create a visualization for the number of matches between all images. (1.0)\n",
    "For example: https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fba504-a871-4287-9833-46aa1c883637",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab06d62-e966-439e-87d7-5d7ba973bca1",
   "metadata": {},
   "source": [
    "## 2.5 Visualize the keypoints and matches between the two images used in lab 3 using Colmap, how it compares to the results from lab 3? (1.0)\n",
    "#### <span style='color:Green'> You can use the GUI to get the keypoints and matches and then visualize it here, following the same style as in lab 3 to get comparable results. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50cc03b-672c-491c-bd61-e40bcc757f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a4a42-5c40-4983-af8a-2c0ef286ce5d",
   "metadata": {},
   "source": [
    "## 2.6 Triangulate and visualize the 3D points from the keypoints extracted using Colmap on the two images used in lab 3, how it compares to the results from lab 3? (1.0) \n",
    "#### <span style='color:Green'> - Use the triangulation from lab 3 to the get the 3D points and visualize them following the same style. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc66ad-ab36-4192-b93b-8523adfb3620",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eacbca-842d-4d9e-85bd-efc35c5dd15a",
   "metadata": {},
   "source": [
    "## 2.7 Visualize the sparse reconstruction using the 2 images from lab 3, and the complete CASTLE dataset. Comment on the differences between techniques and number of images used. (1.0)\n",
    "#### <span style='color:Green'> - Use the reconstruction from Colmap to the get the 3D points and visualize them following the same style, using two images and the complete dataset. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9504a3-dcbf-4b2b-9ff6-71c5a4584742",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
